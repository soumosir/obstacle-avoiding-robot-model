{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0450f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Helper libraries\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c81d61bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PATH = \"/Users/sdutta7/Documents/mlfinalproject/training_data\"\n",
    "EXT = \"*.csv\"\n",
    "all_csv_files = []\n",
    "for path, subdir, files in os.walk(PATH):\n",
    "    for file in glob(os.path.join(path, EXT)):\n",
    "        all_csv_files.append(file)\n",
    "print(len(all_csv_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5469e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "# define the keras model\n",
    "model_neural = Sequential()\n",
    "model_neural.add(Dense(12, input_dim=21, activation='relu'))\n",
    "model_neural.add(Dense(8, activation='relu'))\n",
    "model_neural.add(Dense(2, activation='sigmoid'))\n",
    "model_neural.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.fit(train_images, train_labels, epochs=10)\n",
    "# test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=1) \n",
    "\n",
    "# print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38a47ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23755, 21) (23755, 2)\n",
      "(23755, 21) (23755, 2)\n",
      "23755/23755 [==============================] - 23s 973us/step - loss: 101.3997 - accuracy: 0.6869s - loss:\n",
      "(24965, 21) (24965, 2)\n",
      "(24965, 21) (24965, 2)\n",
      "24965/24965 [==============================] - 24s 964us/step - loss: 314.6491 - accuracy: 0.6612\n",
      "(34855, 21) (34855, 2)\n",
      "(34855, 21) (34855, 2)\n",
      "34855/34855 [==============================] - 34s 971us/step - loss: 351.1012 - accuracy: 0.6235\n",
      "(25933, 21) (25933, 2)\n",
      "(25933, 21) (25933, 2)\n",
      "25933/25933 [==============================] - 25s 964us/step - loss: 747.8964 - accuracy: 0.6922\n",
      "(28378, 21) (28378, 2)\n",
      "(28378, 21) (28378, 2)\n",
      "28378/28378 [==============================] - 28s 969us/step - loss: 854.0313 - accuracy: 0.6200\n",
      "(25384, 21) (25384, 2)\n",
      "(25384, 21) (25384, 2)\n",
      "25384/25384 [==============================] - 26s 1ms/step - loss: 2426.3247 - accuracy: 0.6600\n",
      "(34641, 21) (34641, 2)\n",
      "(34641, 21) (34641, 2)\n",
      "34641/34641 [==============================] - 36s 1ms/step - loss: 2331.7207 - accuracy: 0.5942\n",
      "(26785, 21) (26785, 2)\n",
      "(26785, 21) (26785, 2)\n",
      "26785/26785 [==============================] - 27s 997us/step - loss: 2092.7056 - accuracy: 0.6903\n",
      "(31538, 21) (31538, 2)\n",
      "(31538, 21) (31538, 2)\n",
      "31538/31538 [==============================] - 31s 992us/step - loss: 4766.6660 - accuracy: 0.68270s - loss: 4768.1890 - accuracy:\n",
      "(24045, 21) (24045, 2)\n",
      "(24045, 21) (24045, 2)\n",
      "24045/24045 [==============================] - 24s 1ms/step - loss: 3179.7153 - accuracy: 0.6852\n",
      "(80633, 21) (80633, 2)\n",
      "(80633, 21) (80633, 2)\n",
      "80633/80633 [==============================] - 82s 1ms/step - loss: 4828.3906 - accuracy: 0.6222\n",
      "(23961, 21) (23961, 2)\n",
      "(23961, 21) (23961, 2)\n",
      "23961/23961 [==============================] - 24s 1ms/step - loss: 9736.8574 - accuracy: 0.6560\n",
      "(37573, 21) (37573, 2)\n",
      "(37573, 21) (37573, 2)\n",
      "37573/37573 [==============================] - 39s 1ms/step - loss: 5113.2354 - accuracy: 0.6556\n",
      "(51771, 21) (51771, 2)\n",
      "(51771, 21) (51771, 2)\n",
      "51771/51771 [==============================] - 55s 1ms/step - loss: 11195.1465 - accuracy: 0.6192\n",
      "(15718, 21) (15718, 2)\n",
      "(15718, 21) (15718, 2)\n",
      "15718/15718 [==============================] - 16s 1ms/step - loss: 17045.1211 - accuracy: 0.7082\n",
      "(35212, 21) (35212, 2)\n",
      "(35212, 21) (35212, 2)\n",
      "35212/35212 [==============================] - 37s 1ms/step - loss: 15707.3506 - accuracy: 0.6146\n",
      "(32478, 21) (32478, 2)\n",
      "(32478, 21) (32478, 2)\n",
      "32478/32478 [==============================] - 33s 1ms/step - loss: 18552.2910 - accuracy: 0.6161\n",
      "(27907, 21) (27907, 2)\n",
      "(27907, 21) (27907, 2)\n",
      "27907/27907 [==============================] - 30s 1ms/step - loss: 21092.3691 - accuracy: 0.6588\n",
      "(26934, 21) (26934, 2)\n",
      "(26934, 21) (26934, 2)\n",
      "26934/26934 [==============================] - 29s 1ms/step - loss: 24981.5215 - accuracy: 0.6223\n",
      "(30393, 21) (30393, 2)\n",
      "(30393, 21) (30393, 2)\n",
      "30393/30393 [==============================] - 32s 1ms/step - loss: 34812.9531 - accuracy: 0.6679\n",
      "(24595, 21) (24595, 2)\n",
      "(24595, 21) (24595, 2)\n",
      "24595/24595 [==============================] - 26s 1ms/step - loss: 22998.2832 - accuracy: 0.6529 0s - loss: 22892.8027 - accu\n",
      "(24073, 21) (24073, 2)\n",
      "(24073, 21) (24073, 2)\n",
      "24073/24073 [==============================] - 25s 1ms/step - loss: 28068.7070 - accuracy: 0.6477\n",
      "(30950, 21) (30950, 2)\n",
      "(30950, 21) (30950, 2)\n",
      "30950/30950 [==============================] - 34s 1ms/step - loss: 13928.3135 - accuracy: 0.6332\n",
      "(26319, 21) (26319, 2)\n",
      "(26319, 21) (26319, 2)\n",
      "26319/26319 [==============================] - 27s 1ms/step - loss: 11893.1084 - accuracy: 0.6339\n",
      "(28273, 21) (28273, 2)\n",
      "(28273, 21) (28273, 2)\n",
      "28273/28273 [==============================] - 29s 1ms/step - loss: 22286.2832 - accuracy: 0.6242 0s - loss: 22343\n",
      "(26394, 21) (26394, 2)\n",
      "(26394, 21) (26394, 2)\n",
      "26394/26394 [==============================] - 27s 1ms/step - loss: 18988.1074 - accuracy: 0.6183\n",
      "(25425, 21) (25425, 2)\n",
      "(25425, 21) (25425, 2)\n",
      "25425/25425 [==============================] - 26s 1ms/step - loss: 25668.8145 - accuracy: 0.6313\n",
      "(24874, 21) (24874, 2)\n",
      "(24874, 21) (24874, 2)\n",
      "24874/24874 [==============================] - 29s 1ms/step - loss: 28103.2422 - accuracy: 0.6392\n",
      "(22168, 21) (22168, 2)\n",
      "(22168, 21) (22168, 2)\n",
      "22168/22168 [==============================] - 23s 1ms/step - loss: 43446.3711 - accuracy: 0.6522\n",
      "(23270, 21) (23270, 2)\n",
      "(23270, 21) (23270, 2)\n",
      "23270/23270 [==============================] - 24s 1ms/step - loss: 50550.4492 - accuracy: 0.6087\n",
      "(23752, 21) (23752, 2)\n",
      "(23752, 21) (23752, 2)\n",
      "23752/23752 [==============================] - 25s 1ms/step - loss: 39931.1055 - accuracy: 0.6122\n",
      "(23639, 21) (23639, 2)\n",
      "(23639, 21) (23639, 2)\n",
      "23639/23639 [==============================] - 26s 1ms/step - loss: 54488.7227 - accuracy: 0.6901 2s - loss: 55337.9648  - ETA: 1s - loss: 55396.0508 - accuracy: 0. - ETA: 1s - loss: 55300.2539 \n",
      "(33226, 21) (33226, 2)\n",
      "(33226, 21) (33226, 2)\n",
      "33226/33226 [==============================] - 34s 1ms/step - loss: 40573.7930 - accuracy: 0.6414\n",
      "(29858, 21) (29858, 2)\n",
      "(29858, 21) (29858, 2)\n",
      "29858/29858 [==============================] - 32s 1ms/step - loss: 32458.2109 - accuracy: 0.6239\n",
      "(28215, 21) (28215, 2)\n",
      "(28215, 21) (28215, 2)\n",
      "28215/28215 [==============================] - 34s 1ms/step - loss: 43792.9453 - accuracy: 0.6486 1s - loss: 43604.6484 - accura - ETA: 1s - loss: 43531.5469  - ETA: 0s - loss: 43811.2617 - accu\n",
      "(32337, 21) (32337, 2)\n",
      "(32337, 21) (32337, 2)\n",
      "32337/32337 [==============================] - 27s 832us/step - loss: 64540.5312 - accuracy: 0.6111\n",
      "(24694, 21) (24694, 2)\n",
      "(24694, 21) (24694, 2)\n",
      "24694/24694 [==============================] - 20s 818us/step - loss: 39598.3516 - accuracy: 0.6067\n",
      "(27677, 21) (27677, 2)\n",
      "(27677, 21) (27677, 2)\n",
      "27677/27677 [==============================] - 24s 854us/step - loss: 52119.2383 - accuracy: 0.6388\n",
      "(29125, 21) (29125, 2)\n",
      "(29125, 21) (29125, 2)\n",
      "29125/29125 [==============================] - 24s 837us/step - loss: 55020.1953 - accuracy: 0.6259\n",
      "(27909, 21) (27909, 2)\n",
      "(27909, 21) (27909, 2)\n",
      "27909/27909 [==============================] - 23s 837us/step - loss: 63212.6016 - accuracy: 0.6193\n",
      "(25354, 21) (25354, 2)\n",
      "(25354, 21) (25354, 2)\n",
      "25354/25354 [==============================] - 21s 820us/step - loss: 36119.6094 - accuracy: 0.6714s - loss: 36048.6641  - ETA: 0s -\n",
      "(14777, 21) (14777, 2)\n",
      "(14777, 21) (14777, 2)\n",
      "14777/14777 [==============================] - 17s 1ms/step - loss: 51700.6562 - accuracy: 0.7610 \n",
      "(20654, 21) (20654, 2)\n",
      "(20654, 21) (20654, 2)\n",
      "20654/20654 [==============================] - 24s 1ms/step - loss: 87577.2969 - accuracy: 0.7282\n",
      "(32281, 21) (32281, 2)\n",
      "(32281, 21) (32281, 2)\n",
      "32281/32281 [==============================] - 37s 1ms/step - loss: 127065.3594 - accuracy: 0.7319: 9s - loss: 126265.6797  \n",
      "(14723, 21) (14723, 2)\n",
      "(14723, 21) (14723, 2)\n",
      "14723/14723 [==============================] - 16s 1ms/step - loss: 77552.8125 - accuracy: 0.7263\n",
      "(12281, 21) (12281, 2)\n",
      "(12281, 21) (12281, 2)\n",
      "12281/12281 [==============================] - 13s 1ms/step - loss: 75031.2656 - accuracy: 0.7389\n",
      "(18222, 21) (18222, 2)\n",
      "(18222, 21) (18222, 2)\n",
      "18222/18222 [==============================] - 19s 1ms/step - loss: 109635.5156 - accuracy: 0.7404\n",
      "(14342, 21) (14342, 2)\n",
      "(14342, 21) (14342, 2)\n",
      "14342/14342 [==============================] - 19s 1ms/step - loss: 130991.6016 - accuracy: 0.7134\n",
      "(13175, 21) (13175, 2)\n",
      "(13175, 21) (13175, 2)\n",
      "13175/13175 [==============================] - 14s 1ms/step - loss: 101551.7734 - accuracy: 0.7360\n",
      "(12527, 21) (12527, 2)\n",
      "(12527, 21) (12527, 2)\n",
      "12527/12527 [==============================] - 14s 1ms/step - loss: 169766.1094 - accuracy: 0.7233\n",
      "(11131, 21) (11131, 2)\n",
      "(11131, 21) (11131, 2)\n",
      "11131/11131 [==============================] - 13s 1ms/step - loss: 111054.4062 - accuracy: 0.7408: 5s - ETA: 1s - loss: 105520\n",
      "(32051, 21) (32051, 2)\n",
      "(32051, 21) (32051, 2)\n",
      "32051/32051 [==============================] - 37s 1ms/step - loss: 108663.8906 - accuracy: 0.7390: 0s - loss: 108001.8281 - accuracy - ETA: 0s - loss: 108255.0312 - accuracy: 0.7\n",
      "(28489, 21) (28489, 2)\n",
      "(28489, 21) (28489, 2)\n",
      "28489/28489 [==============================] - 32s 1ms/step - loss: 162009.3906 - accuracy: 0.6992: 1s - loss: 163955\n",
      "(30226, 21) (30226, 2)\n",
      "(30226, 21) (30226, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30226/30226 [==============================] - 29s 971us/step - loss: 128733.4297 - accuracy: 0.7012A: 3s - ETA: 1s - loss: 129605.0625 - accura - ETA: 1s - loss\n",
      "(23897, 21) (23897, 2)\n",
      "(23897, 21) (23897, 2)\n",
      "23897/23897 [==============================] - 23s 967us/step - loss: 121314.9922 - accuracy: 0.6971\n",
      "(23191, 21) (23191, 2)\n",
      "(23191, 21) (23191, 2)\n",
      "23191/23191 [==============================] - 23s 974us/step - loss: 171669.3438 - accuracy: 0.71243s - loss: 169899.0781 - - ETA: 2s - loss: 168698.9844 - accu - ETA: 1s - los\n",
      "(32018, 21) (32018, 2)\n",
      "(32018, 21) (32018, 2)\n",
      "32018/32018 [==============================] - 34s 1ms/step - loss: 150038.7188 - accuracy: 0.6989:\n",
      "(32547, 21) (32547, 2)\n",
      "(32547, 21) (32547, 2)\n",
      "32547/32547 [==============================] - 36s 1ms/step - loss: 189796.0938 - accuracy: 0.6988:  - ETA: 3s - loss: 187785.3281 - accuracy: 0. - ETA: 3s - loss: 188907.0938 - - ETA: 2s - loss: 188118.5625 - accurac - ETA: 2s - loss:  - ETA: 1s\n",
      "(39594, 21) (39594, 2)\n",
      "(39594, 21) (39594, 2)\n",
      "39594/39594 [==============================] - 41s 1ms/step - loss: 144345.2344 - accuracy: 0.6449\n",
      "(33556, 21) (33556, 2)\n",
      "(33556, 21) (33556, 2)\n",
      "33556/33556 [==============================] - 31s 931us/step - loss: 165644.2344 - accuracy: 0.7305\n",
      "(30958, 21) (30958, 2)\n",
      "(30958, 21) (30958, 2)\n",
      "30958/30958 [==============================] - 35s 1ms/step - loss: 151577.9219 - accuracy: 0.6688\n",
      "(23580, 21) (23580, 2)\n",
      "(23580, 21) (23580, 2)\n",
      "23580/23580 [==============================] - 24s 1ms/step - loss: 184758.0938 - accuracy: 0.7214: 3s - loss: 180798.0781 - accu - ETA: 2s - loss: 181486.8594  - ETA: 1s -  - ETA: 0s - loss: 184812.0938 - accuracy: 0.72\n",
      "(33423, 21) (33423, 2)\n",
      "(33423, 21) (33423, 2)\n",
      "33423/33423 [==============================] - 33s 998us/step - loss: 239680.0781 - accuracy: 0.6864\n",
      "(24292, 21) (24292, 2)\n",
      "(24292, 21) (24292, 2)\n",
      "24292/24292 [==============================] - 24s 976us/step - loss: 188677.5000 - accuracy: 0.71030s - loss: 188238.9688 - ac\n",
      "(23754, 21) (23754, 2)\n",
      "(23754, 21) (23754, 2)\n",
      "23754/23754 [==============================] - 27s 1ms/step - loss: 229516.8750 - accuracy: 0.7041: 4s - loss: 22\n",
      "(26109, 21) (26109, 2)\n",
      "(26109, 21) (26109, 2)\n",
      "26109/26109 [==============================] - 25s 954us/step - loss: 169109.6250 - accuracy: 0.69322\n",
      "(26579, 21) (26579, 2)\n",
      "(26579, 21) (26579, 2)\n",
      "26579/26579 [==============================] - 26s 976us/step - loss: 204721.7344 - accuracy: 0.6945\n",
      "(45105, 21) (45105, 2)\n",
      "(45105, 21) (45105, 2)\n",
      "45105/45105 [==============================] - 45s 995us/step - loss: 149717.6094 - accuracy: 0.6605\n",
      "(38563, 21) (38563, 2)\n",
      "(38563, 21) (38563, 2)\n",
      "38563/38563 [==============================] - 39s 1ms/step - loss: 243040.2344 - accuracy: 0.7055\n",
      "(33593, 21) (33593, 2)\n",
      "(33593, 21) (33593, 2)\n",
      "33593/33593 [==============================] - 33s 981us/step - loss: 269924.8438 - accuracy: 0.73841s - loss: 2\n",
      "(40527, 21) (40527, 2)\n",
      "(40527, 21) (40527, 2)\n",
      "40527/40527 [==============================] - 40s 980us/step - loss: 189361.6406 - accuracy: 0.6389\n",
      "(38072, 21) (38072, 2)\n",
      "(38072, 21) (38072, 2)\n",
      "38072/38072 [==============================] - 40s 1ms/step - loss: 186691.0312 - accuracy: 0.6437\n",
      "(26345, 21) (26345, 2)\n",
      "(26345, 21) (26345, 2)\n",
      "26345/26345 [==============================] - 24s 926us/step - loss: 205568.8125 - accuracy: 0.63039s - loss: 202 - ETA: 7s - loss: 202196.7812 - accu - ETA: 6s - los - E\n",
      "(34570, 21) (34570, 2)\n",
      "(34570, 21) (34570, 2)\n",
      "34570/34570 [==============================] - 32s 936us/step - loss: 145251.2188 - accuracy: 0.6513\n",
      "(34369, 21) (34369, 2)\n",
      "(34369, 21) (34369, 2)\n",
      "34369/34369 [==============================] - 31s 915us/step - loss: 178660.5625 - accuracy: 0.63411s - loss: 179136.84\n",
      "(32093, 21) (32093, 2)\n",
      "(32093, 21) (32093, 2)\n",
      "32093/32093 [==============================] - 32s 995us/step - loss: 243403.2031 - accuracy: 0.6510\n",
      "(36328, 21) (36328, 2)\n",
      "(36328, 21) (36328, 2)\n",
      "36328/36328 [==============================] - 29s 806us/step - loss: 247448.6094 - accuracy: 0.65531s - loss: 248416\n",
      "(29602, 21) (29602, 2)\n",
      "(29602, 21) (29602, 2)\n",
      "29602/29602 [==============================] - 30s 1ms/step - loss: 206853.2344 - accuracy: 0.6321\n",
      "(21586, 21) (21586, 2)\n",
      "(21586, 21) (21586, 2)\n",
      "21586/21586 [==============================] - 21s 986us/step - loss: 278209.5000 - accuracy: 0.6688\n",
      "(24663, 21) (24663, 2)\n",
      "(24663, 21) (24663, 2)\n",
      "24663/24663 [==============================] - 25s 1ms/step - loss: 394798.3438 - accuracy: 0.6821\n",
      "(19934, 21) (19934, 2)\n",
      "(19934, 21) (19934, 2)\n",
      "19934/19934 [==============================] - 19s 967us/step - loss: 295173.7500 - accuracy: 0.7227\n",
      "(31764, 21) (31764, 2)\n",
      "(31764, 21) (31764, 2)\n",
      "31764/31764 [==============================] - 37s 1ms/step - loss: 323202.6875 - accuracy: 0.7327: 3s - loss: 316051.0312 - accuracy: 0\n",
      "(6083, 21) (6083, 2)\n",
      "(6083, 21) (6083, 2)\n",
      "6083/6083 [==============================] - 6s 1ms/step - loss: 313612.6250 - accuracy: 0.7161A: 2s - loss: 3634 - ETA: 0s - loss: 335530.6250 - accuracy: 0.717 - ETA: 0s - loss: 342952.7188 - \n",
      "(33787, 21) (33787, 2)\n",
      "(33787, 21) (33787, 2)\n",
      "33787/33787 [==============================] - 35s 1ms/step - loss: 272043.2188 - accuracy: 0.7062: 0s - loss: 268820.0938 - accura\n",
      "(7960, 21) (7960, 2)\n",
      "(7960, 21) (7960, 2)\n",
      "7960/7960 [==============================] - 8s 1ms/step - loss: 583858.9375 - accuracy: 0.6405A: 1s - loss: 595614.8125 -  - ETA: 0s - loss: 573180.4375 - accuracy: 0.\n",
      "(23879, 21) (23879, 2)\n",
      "(23879, 21) (23879, 2)\n",
      "23879/23879 [==============================] - 24s 1ms/step - loss: 260779.6406 - accuracy: 0.7155: 0s - loss: 258219.9062 -\n",
      "(7884, 21) (7884, 2)\n",
      "(7884, 21) (7884, 2)\n",
      "7884/7884 [==============================] - 8s 1ms/step - loss: 354754.7500 - accuracy: 0.6161A: 0s - loss: 352211.3125 - a\n",
      "(34815, 21) (34815, 2)\n",
      "(34815, 21) (34815, 2)\n",
      "34815/34815 [==============================] - 36s 1ms/step - loss: 365978.6250 - accuracy: 0.7106\n",
      "(32792, 21) (32792, 2)\n",
      "(32792, 21) (32792, 2)\n",
      "32792/32792 [==============================] - 34s 1ms/step - loss: 254236.0781 - accuracy: 0.7296: 4 - \n",
      "(13169, 21) (13169, 2)\n",
      "(13169, 21) (13169, 2)\n",
      "13169/13169 [==============================] - 14s 1ms/step - loss: 387251.3125 - accuracy: 0.7610: 1s - loss: 393892.7812 - ac - ETA: 0s - loss: 384853.7500 - ac\n",
      "(17867, 21) (17867, 2)\n",
      "(17867, 21) (17867, 2)\n",
      "17867/17867 [==============================] - 21s 1ms/step - loss: 412045.3750 - accuracy: 0.7464\n",
      "(12935, 21) (12935, 2)\n",
      "(12935, 21) (12935, 2)\n",
      "12935/12935 [==============================] - 20s 2ms/step - loss: 549957.6875 - accuracy: 0.7220\n",
      "(12196, 21) (12196, 2)\n",
      "(12196, 21) (12196, 2)\n",
      "12196/12196 [==============================] - 22s 2ms/step - loss: 559591.8750 - accuracy: 0.7244\n",
      "(11325, 21) (11325, 2)\n",
      "(11325, 21) (11325, 2)\n",
      "11325/11325 [==============================] - 15s 1ms/step - loss: 547243.6250 - accuracy: 0.7420\n",
      "(20100, 21) (20100, 2)\n",
      "(20100, 21) (20100, 2)\n",
      "20100/20100 [==============================] - 20s 1ms/step - loss: 383756.2500 - accuracy: 0.7498: 3s - l\n",
      "(14194, 21) (14194, 2)\n",
      "(14194, 21) (14194, 2)\n",
      "14194/14194 [==============================] - 15s 1ms/step - loss: 445420.4375 - accuracy: 0.7486\n",
      "(18394, 21) (18394, 2)\n",
      "(18394, 21) (18394, 2)\n",
      "18394/18394 [==============================] - 17s 901us/step - loss: 438923.5625 - accuracy: 0.7525\n",
      "(11997, 21) (11997, 2)\n",
      "(11997, 21) (11997, 2)\n",
      "11997/11997 [==============================] - 10s 835us/step - loss: 324082.6562 - accuracy: 0.7603\n",
      "(11888, 21) (11888, 2)\n",
      "(11888, 21) (11888, 2)\n",
      "11888/11888 [==============================] - 10s 868us/step - loss: 456607.3125 - accuracy: 0.73861s - loss: 467280.5000 - accuracy - ETA: 1s - loss: 453375.7\n",
      "(13152, 21) (13152, 2)\n",
      "(13152, 21) (13152, 2)\n",
      "13152/13152 [==============================] - 12s 920us/step - loss: 406529.0625 - accuracy: 0.7570\n",
      "(13012, 21) (13012, 2)\n",
      "(13012, 21) (13012, 2)\n",
      "13012/13012 [==============================] - 16s 1ms/step - loss: 467395.9062 - accuracy: 0.7625\n",
      "(12894, 21) (12894, 2)\n",
      "(12894, 21) (12894, 2)\n",
      "12894/12894 [==============================] - 11s 877us/step - loss: 469525.8750 - accuracy: 0.7452\n",
      "(14287, 21) (14287, 2)\n",
      "(14287, 21) (14287, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14287/14287 [==============================] - 12s 860us/step - loss: 653991.6875 - accuracy: 0.73090s - loss: 651993.7500 - accur\n",
      "(19849, 21) (19849, 2)\n",
      "(19849, 21) (19849, 2)\n",
      "19849/19849 [==============================] - 17s 844us/step - loss: 524823.6250 - accuracy: 0.7420\n",
      "(20400, 21) (20400, 2)\n",
      "(20400, 21) (20400, 2)\n",
      "20400/20400 [==============================] - 18s 861us/step - loss: 492752.5000 - accuracy: 0.74362s - loss: 464887.3750 - accuracy: 0 -\n",
      "(21044, 21) (21044, 2)\n",
      "(21044, 21) (21044, 2)\n",
      "21044/21044 [==============================] - 18s 849us/step - loss: 473175.8438 - accuracy: 0.7510\n",
      "(18114, 21) (18114, 2)\n",
      "(18114, 21) (18114, 2)\n",
      "18114/18114 [==============================] - 15s 852us/step - loss: 616052.6250 - accuracy: 0.7472\n",
      "INFO:tensorflow:Assets written to: ram://2442f364-3fd8-47e0-bdfb-8fe5f68e98c7/assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "headers = []\n",
    "with open('config.json') as f:\n",
    "    headers = json.load(f)\n",
    "X = []\n",
    "y = []\n",
    "for path in all_csv_files:    \n",
    "    df = pd.read_csv(path,names=headers)\n",
    "    \n",
    "    arr1_120 = [ 'Laser'+str(i+1) for i in range(0,120)]\n",
    "    df['laser_1_120'] = df[arr1_120].mean(axis=1)   \n",
    "\n",
    "    arr121_240 = [ 'Laser'+str(i+1) for i in range(120,240)]\n",
    "    df['laser_121_240'] = df[arr121_240].mean(axis=1)   \n",
    "\n",
    "    arr241_360 = [ 'Laser'+str(i+1) for i in range(240,360)]\n",
    "    df['laser_241_360'] = df[arr241_360].mean(axis=1) \n",
    "\n",
    "    arr361_480 = [ 'Laser'+str(i+1) for i in range(360,480)]\n",
    "    df['laser_361_480'] = df[arr361_480].mean(axis=1)     \n",
    "\n",
    "    arr481_600 = [ 'Laser'+str(i+1) for i in range(480,600)]\n",
    "    df['laser_481_600'] = df[arr481_600].mean(axis=1)    \n",
    "\n",
    "    arr601_720 = [ 'Laser'+str(i+1) for i in range(600,720)]\n",
    "    df['laser_601_720'] = df[arr601_720].mean(axis=1)  \n",
    "    arr721_840 = [ 'Laser'+str(i+1) for i in range(720,840)]\n",
    "    df['laser_721_840'] = df[arr721_840].mean(axis=1)  \n",
    "\n",
    "    arr841_960 = [ 'Laser'+str(i+1) for i in range(840,960)]\n",
    "    df['laser_841_960'] = df[arr841_960].mean(axis=1)  \n",
    "\n",
    "    arr961_1080 = [ 'Laser'+str(i+1) for i in range(960,1080)]\n",
    "    df['laser_961_1080'] = df[arr961_1080].mean(axis=1)  \n",
    "    \n",
    "    df = df.iloc[: , 1080:]\n",
    "    X = df[[\"Final_goal_x\",\"Final_goal_y\",\"Final_goal_qk\",\"Final_goal_qr\",\"Local_goal_x\",\"Local_goal_y\",\"Local_goal_qk\",\"Local_goal_qr\",\"Robot_pos_x\",\"Robot_pos_y\",\"Robot_pos_qr\",\"Robot_pos_qk\",\"laser_1_120\",\"laser_121_240\",\"laser_241_360\",\"laser_361_480\",\"laser_481_600\",\"laser_601_720\",\"laser_721_840\",\"laser_841_960\",\"laser_961_1080\"]]\n",
    "    y = df[[\"Cmd_vel_v\",\"Cmd_vel_w\"]]\n",
    "    print(X.shape,y.shape)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "#     X = np.reshape(X, (X.shape[0],X.shape[1]))\n",
    "#     y = np.reshape(y, (y.shape[0],y.shape[1]))\n",
    "    print(X.shape,y.shape)\n",
    "    \n",
    "    model_neural.fit(X, y, batch_size=1,epochs=1)\n",
    "#     break\n",
    "#     model.fit(X, y)\n",
    "    # fit the model on the whole dataset\n",
    "#     wrapper_svr.fit(X, y)  \n",
    "    \n",
    "#     model_KN.fit(X, y)\n",
    "    \n",
    "#     model_DT.fit(X, y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pickle.dump(model_neural, open('finalized_robot_nural.sav', 'wb')) \n",
    "# # pickle.dump(wrapper_svr, open('finalized_robot_svr.sav', 'wb'))\n",
    "# pickle.dump(model_KN, open('finalized_robot_kn.sav', 'wb'))\n",
    "# pickle.dump(model_KN, open('finalized_robot_dt.sav', 'wb'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "05304a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18114, 2) (18114, 2) (18114, 21)\n",
      " r2 score -lr  0.23631484966394392\n",
      " r2 score -dt  0.9641781674090435\n",
      " r2 score -kn  0.9641781674090435\n"
     ]
    }
   ],
   "source": [
    "Ein = 0\n",
    "model_linear = pickle.load(open('finalized_robot_linear.sav', 'rb'))\n",
    "model_dt = pickle.load(open('finalized_robot_dt.sav', 'rb'))\n",
    "model_kn = pickle.load(open('finalized_robot_kn.sav', 'rb'))\n",
    "model_nural = pickle.load(open('finalized_robot_nural.sav', 'rb'))\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "y_pred = model_linear.predict(X)\n",
    "rms = mean_squared_error(y, y_predicted, squared=False)\n",
    "print(\" rms score -lr \",rms)\n",
    "text = 'In-sample rms with linear regression:'+ str(rms)\n",
    "\n",
    "y_pred = model_kn.predict(X)\n",
    "rms = mean_squared_error(y, y_predicted, squared=False)\n",
    "print(\" rms score -kn \",rms)\n",
    "text += 'In-sample rms with kn:'+ str(rms)\n",
    "\n",
    "y_pred = model_nural.predict(X_np)\n",
    "rms = mean_squared_error(y_np, y_predicted, squared=False)\n",
    "print(\" rms score -lr \",rms)\n",
    "text += 'In-sample rms with nn:'+ str(rms)\n",
    "\n",
    "with open('Ein_test.txt', 'w') as f:\n",
    "    f.write(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2398275d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
